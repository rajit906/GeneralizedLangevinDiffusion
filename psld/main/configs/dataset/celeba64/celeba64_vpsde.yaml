diffusion:
  data:
    root: ???
    name: "cifar10"
    image_size: 64
    hflip: True
    num_channels: 3
    norm: True

  model:
    score_fn:
      name: "ncsnpp"
      in_ch: 3
      out_ch: 3
      nonlinearity: "swish"
      nf : 128
      ch_mult: [1,2,2,2,4]
      num_res_blocks: 2
      attn_resolutions: [16,]
      dropout: 0.1
      resamp_with_conv: True
      noise_cond: True
      fir: False
      fir_kernel: [1,3,3,1]
      skip_rescale: True
      resblock_type: "biggan"
      progressive: "none"
      progressive_input: "none"
      progressive_combine: "sum"
      embedding_type: "positional"
      init_scale: 0.0
      fourier_scale: 16
      # scale_by_sigma: False  (The Unet always predicts epsilon)
      # n_heads: 8
    sde:
      name: "vpsde"
      beta_min: 0.1
      beta_max: 20
      n_timesteps: 1000
      is_augmented: False

  training:
    seed: 0
    continuous: True
    loss:
      name: "score_loss"
      l_type: "l2"
      reduce_mean: True
      weighting: "fid"
    optimizer:
      name: "Adam"
      lr: 2e-4
      beta_1: 0.9
      beta_2: 0.999
      weight_decay: 0
      eps: 1e-8
      warmup: 5000
      grad_clip: 1.0
    train_eps: 1e-5
    fp16: False
    use_ema: True
    ema_decay: 0.9999
    batch_size: 32
    epochs: 5000
    log_step: 1
    accelerator: "gpu"
    devices: [0]
    chkpt_interval: 1
    restore_path: ""
    results_dir: ???
    workers: 1
    chkpt_prefix: ""

  evaluation:
    # Sampler specific config goes here
    sampler:
      name: em_sde
    seed: 0
    chkpt_path: ???
    save_path: ???
    n_discrete_steps: 1000
    denoise: True
    eval_eps: 1e-3
    stride_type: uniform
    use_pflow: False
    sample_from: "target"
    accelerator: "gpu"
    devices: [0]
    n_samples: 50000
    workers: 2
    batch_size: 64
    save_mode: image
    sample_prefix: "gpu"

# VAE config used for VAE training
vae:
  data:
    root: ???
    name: "cifar10"
    image_size: 32
    n_channels: 3
    hflip: False

  model:
    enc_block_config : "32x7,32d2,32t16,16x4,16d2,16t8,8x4,8d2,8t4,4x3,4d4,4t1,1x3"
    enc_channel_config: "32:64,16:128,8:256,4:256,1:512"
    dec_block_config: "1x1,1u4,1t4,4x2,4u2,4t8,8x3,8u2,8t16,16x7,16u2,16t32,32x15"
    dec_channel_config: "32:64,16:128,8:256,4:256,1:512"

  training:
    seed: 0
    fp16: False
    batch_size: 128
    epochs: 1000
    log_step: 1
    device: "gpu:0"
    chkpt_interval: 1
    optimizer: "Adam"
    lr: 1e-4
    restore_path: ""
    results_dir: ???
    workers: 2
    chkpt_prefix: ""
    alpha: 1.0
